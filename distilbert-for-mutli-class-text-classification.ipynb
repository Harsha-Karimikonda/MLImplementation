{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"dockerImageVersionId":29987,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:00.864355Z","iopub.execute_input":"2024-07-22T15:07:00.864753Z","iopub.status.idle":"2024-07-22T15:07:00.870119Z","shell.execute_reply.started":"2024-07-22T15:07:00.864717Z","shell.execute_reply":"2024-07-22T15:07:00.869148Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv')\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:01.146630Z","iopub.execute_input":"2024-07-22T15:07:01.147010Z","iopub.status.idle":"2024-07-22T15:07:01.454431Z","shell.execute_reply.started":"2024-07-22T15:07:01.146970Z","shell.execute_reply":"2024-07-22T15:07:01.453631Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                          statement   status\n0           0                                         oh my gosh  Anxiety\n1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n3           3  I've shifted my focus to something else but I'...  Anxiety\n4           4  I'm restless and restless, it's been a month n...  Anxiety","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh my gosh</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>trouble sleeping, confused mind, restless hear...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I've shifted my focus to something else but I'...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I'm restless and restless, it's been a month n...</td>\n      <td>Anxiety</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(df['status'])\ndf['status'] = encoded_labels\nprint(df['status'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:01.456212Z","iopub.execute_input":"2024-07-22T15:07:01.456502Z","iopub.status.idle":"2024-07-22T15:07:01.481915Z","shell.execute_reply.started":"2024-07-22T15:07:01.456474Z","shell.execute_reply":"2024-07-22T15:07:01.481086Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"3    16351\n2    15404\n6    10653\n0     3888\n1     2877\n5     2669\n4     1201\nName: status, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df['status'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:01.973917Z","iopub.execute_input":"2024-07-22T15:07:01.974253Z","iopub.status.idle":"2024-07-22T15:07:01.981874Z","shell.execute_reply.started":"2024-07-22T15:07:01.974225Z","shell.execute_reply":"2024-07-22T15:07:01.980965Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"3    16351\n2    15404\n6    10653\n0     3888\n1     2877\n5     2669\n4     1201\nName: status, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:02.724312Z","iopub.execute_input":"2024-07-22T15:07:02.724719Z","iopub.status.idle":"2024-07-22T15:07:02.729316Z","shell.execute_reply.started":"2024-07-22T15:07:02.724682Z","shell.execute_reply":"2024-07-22T15:07:02.728358Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentenceDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',  \n            truncation=True,      \n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:03.898286Z","iopub.execute_input":"2024-07-22T15:07:03.898614Z","iopub.status.idle":"2024-07-22T15:07:03.908760Z","shell.execute_reply.started":"2024-07-22T15:07:03.898586Z","shell.execute_reply":"2024-07-22T15:07:03.907721Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn(batch):\n    input_ids = [item['input_ids'] for item in batch]\n    attention_mask = [item['attention_mask'] for item in batch]\n    labels = [item['labels'] for item in batch]\n    \n    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n    labels = torch.stack(labels)\n    \n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'labels': labels\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:04.659235Z","iopub.execute_input":"2024-07-22T15:07:04.659573Z","iopub.status.idle":"2024-07-22T15:07:04.667212Z","shell.execute_reply.started":"2024-07-22T15:07:04.659546Z","shell.execute_reply":"2024-07-22T15:07:04.666314Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nMAX_LEN = 512\nBATCH_SIZE = 16\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:05.464614Z","iopub.execute_input":"2024-07-22T15:07:05.464964Z","iopub.status.idle":"2024-07-22T15:07:05.727644Z","shell.execute_reply.started":"2024-07-22T15:07:05.464932Z","shell.execute_reply":"2024-07-22T15:07:05.726975Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"class DistilBertClass(torch.nn.Module):\n    def __init__(self):\n        super(DistilBertClass, self).__init__()\n        self.l1 = DistilBertModel.from_pretrained('distilbert-base-uncased')\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.2)\n        self.classifier = torch.nn.Linear(768, 7)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, input_ids, attention_mask):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = self.relu(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:06.099600Z","iopub.execute_input":"2024-07-22T15:07:06.099963Z","iopub.status.idle":"2024-07-22T15:07:06.109227Z","shell.execute_reply.started":"2024-07-22T15:07:06.099930Z","shell.execute_reply":"2024-07-22T15:07:06.108437Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"statement = df['statement'].tolist()\nstatus = df['status'].tolist()\ntrain_text, test_text, train_label, test_label = train_test_split(statement, status, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:07.417444Z","iopub.execute_input":"2024-07-22T15:07:07.417812Z","iopub.status.idle":"2024-07-22T15:07:07.467418Z","shell.execute_reply.started":"2024-07-22T15:07:07.417775Z","shell.execute_reply":"2024-07-22T15:07:07.466786Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Create datasets and dataloaders\ntrain_dataset = SentenceDataset(train_text, train_label, tokenizer, MAX_LEN)\ntest_dataset = SentenceDataset(test_text, test_label, tokenizer, MAX_LEN)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:08.295993Z","iopub.execute_input":"2024-07-22T15:07:08.296322Z","iopub.status.idle":"2024-07-22T15:07:08.303687Z","shell.execute_reply.started":"2024-07-22T15:07:08.296293Z","shell.execute_reply":"2024-07-22T15:07:08.302541Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"model = DistilBertClass()\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:09.135446Z","iopub.execute_input":"2024-07-22T15:07:09.135778Z","iopub.status.idle":"2024-07-22T15:07:10.480647Z","shell.execute_reply.started":"2024-07-22T15:07:09.135749Z","shell.execute_reply":"2024-07-22T15:07:10.479777Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"DistilBertClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss().to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:10.482448Z","iopub.execute_input":"2024-07-22T15:07:10.482729Z","iopub.status.idle":"2024-07-22T15:07:10.488960Z","shell.execute_reply.started":"2024-07-22T15:07:10.482702Z","shell.execute_reply":"2024-07-22T15:07:10.488148Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"%time\nepochs = 1\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', leave=True)\n    \n    for batch in progress_bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs, labels)  # Calculate loss\n\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        # Update progress bar\n        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    avg_loss = total_loss / len(train_loader)\n    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:07:10.796713Z","iopub.execute_input":"2024-07-22T15:07:10.797055Z","iopub.status.idle":"2024-07-22T15:26:03.522827Z","shell.execute_reply.started":"2024-07-22T15:07:10.797027Z","shell.execute_reply":"2024-07-22T15:26:03.521955Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stderr","text":"Epoch 1/1:   0%|          | 0/2653 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 3 µs, sys: 0 ns, total: 3 µs\nWall time: 6.68 µs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/1: 100%|██████████| 2653/2653 [18:52<00:00,  2.34it/s, loss=1.9787]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/1, Average Loss: 0.6333\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\ncorrect_predictions = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    progress_bar = tqdm(test_loader, desc='Evaluating', leave=True)\n    for batch in progress_bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        correct_predictions += torch.sum(preds == labels)\n        total_samples += labels.size(0)\n        \n        # Update progress bar\n        accuracy = (correct_predictions.double() / total_samples).item() * 100\n        progress_bar.set_postfix({'accuracy': f'{accuracy:.2f}%'})\n\nfinal_accuracy = (correct_predictions.double() / total_samples).item() * 100\nprint(f\"Test Accuracy: {final_accuracy}%\")","metadata":{"execution":{"iopub.status.busy":"2024-07-22T15:26:03.525322Z","iopub.execute_input":"2024-07-22T15:26:03.525712Z","iopub.status.idle":"2024-07-22T15:28:03.851375Z","shell.execute_reply.started":"2024-07-22T15:26:03.525672Z","shell.execute_reply":"2024-07-22T15:28:03.850587Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 664/664 [02:00<00:00,  5.52it/s, accuracy=81.90%]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 81.90215854463192%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}