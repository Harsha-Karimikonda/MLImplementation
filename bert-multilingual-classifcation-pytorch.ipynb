{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2808848,"sourceType":"datasetVersion","datasetId":1709217}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:34.002913Z","iopub.execute_input":"2024-07-21T04:42:34.003788Z","iopub.status.idle":"2024-07-21T04:42:40.760053Z","shell.execute_reply.started":"2024-07-21T04:42:34.003748Z","shell.execute_reply":"2024-07-21T04:42:40.759070Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv',encoding='utf-8')\nsentences=df['comment_text'].tolist()\nlabels=df['toxic'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:40.762078Z","iopub.execute_input":"2024-07-21T04:42:40.762907Z","iopub.status.idle":"2024-07-21T04:42:42.471013Z","shell.execute_reply.started":"2024-07-21T04:42:40.762867Z","shell.execute_reply":"2024-07-21T04:42:42.470233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_texts,test_texts,train_labels,test_labels=train_test_split(sentences,labels,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:42.472014Z","iopub.execute_input":"2024-07-21T04:42:42.472287Z","iopub.status.idle":"2024-07-21T04:42:42.581432Z","shell.execute_reply.started":"2024-07-21T04:42:42.472262Z","shell.execute_reply":"2024-07-21T04:42:42.580729Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SentenceDataset(Dataset):\n    def __init__(self,texts,labels,tokenizer,max_len):\n        self.texts=texts\n        self.labels=labels\n        self.tokenizer=tokenizer\n        self.max_len=max_len\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self,idx):\n        text=str(self.texts[idx])\n        label=self.labels[idx]\n        \n        encoding=self.tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=self.max_len,\n        return_token_type_ids=False,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt',       \n        )\n        \n        return{\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels':torch.tensor(label,dtype=torch.long)\n        }\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:42.582476Z","iopub.execute_input":"2024-07-21T04:42:42.582748Z","iopub.status.idle":"2024-07-21T04:42:42.602928Z","shell.execute_reply.started":"2024-07-21T04:42:42.582723Z","shell.execute_reply":"2024-07-21T04:42:42.601879Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel=AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased',num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:42.606014Z","iopub.execute_input":"2024-07-21T04:42:42.606363Z","iopub.status.idle":"2024-07-21T04:42:47.911015Z","shell.execute_reply.started":"2024-07-21T04:42:42.606339Z","shell.execute_reply":"2024-07-21T04:42:47.910284Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6b8aaa24fd498dbd7cb5443c1869da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ab11b555fd4acc9e8a6e08fb9f69a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40bbf274f0284be6ba2987880e97cb9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcefa7780b904e2a8de003b4e63d62a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5066622f420e43a9bb2d0f31c2b17d13"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LEN=128\nBATCH_SIZE=16","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:47.912082Z","iopub.execute_input":"2024-07-21T04:42:47.912484Z","iopub.status.idle":"2024-07-21T04:42:47.916493Z","shell.execute_reply.started":"2024-07-21T04:42:47.912460Z","shell.execute_reply":"2024-07-21T04:42:47.915662Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset=SentenceDataset(train_texts,train_labels,tokenizer,MAX_LEN)\ntest_dataset=SentenceDataset(test_texts,test_labels,tokenizer,MAX_LEN)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:47.917539Z","iopub.execute_input":"2024-07-21T04:42:47.917830Z","iopub.status.idle":"2024-07-21T04:42:47.932398Z","shell.execute_reply.started":"2024-07-21T04:42:47.917807Z","shell.execute_reply":"2024-07-21T04:42:47.931499Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\ntest_loader=DataLoader(test_dataset,batch_size=BATCH_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:47.933456Z","iopub.execute_input":"2024-07-21T04:42:47.933722Z","iopub.status.idle":"2024-07-21T04:42:47.941630Z","shell.execute_reply.started":"2024-07-21T04:42:47.933700Z","shell.execute_reply":"2024-07-21T04:42:47.940836Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:47.942631Z","iopub.execute_input":"2024-07-21T04:42:47.942883Z","iopub.status.idle":"2024-07-21T04:42:48.314576Z","shell.execute_reply.started":"2024-07-21T04:42:47.942861Z","shell.execute_reply":"2024-07-21T04:42:48.313741Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer=torch.optim.Adam(model.parameters(), lr=1e-5)\nepochs=1","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:48.315822Z","iopub.execute_input":"2024-07-21T04:42:48.316130Z","iopub.status.idle":"2024-07-21T04:42:48.908790Z","shell.execute_reply.started":"2024-07-21T04:42:48.316103Z","shell.execute_reply":"2024-07-21T04:42:48.908051Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    for batch in train_loader:\n        input_ids=batch['input_ids'].to(device)\n        attention_mask=batch['attention_mask'].to(device)\n        labels=batch['labels'].to(device)\n        \n        outputs=model(input_ids,attention_mask=attention_mask,labels=labels)\n        loss=outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    print(f'Epoch {epoch+1}/{epochs} done')","metadata":{"execution":{"iopub.status.busy":"2024-07-21T04:42:48.909838Z","iopub.execute_input":"2024-07-21T04:42:48.910245Z","iopub.status.idle":"2024-07-21T05:20:08.129008Z","shell.execute_reply.started":"2024-07-21T04:42:48.910220Z","shell.execute_reply":"2024-07-21T05:20:08.128004Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/1 done\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions=[]\nactual_labels=[]\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids=batch['input_ids'].to(device)\n        attention_mask=batch['attention_mask'].to(device)\n        labels=batch['labels'].to(device)\n        \n        outputs=model(input_ids,attention_mask=attention_mask)\n        _,preds=torch.max(outputs.logits,dim=1)\n        \n        predictions.extend(preds.cpu().tolist())\n        actual_labels.extend(labels.cpu().tolist())\n        \naccuracy=accuracy_score(actual_labels,predictions)\nprint(f'Accuracy: {accuracy:.2f}')\nprint(classification_report(actual_labels,predictions))","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:29:46.881222Z","iopub.execute_input":"2024-07-21T05:29:46.881610Z","iopub.status.idle":"2024-07-21T05:32:46.009606Z","shell.execute_reply.started":"2024-07-21T05:29:46.881561Z","shell.execute_reply":"2024-07-21T05:32:46.008622Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy: 0.96\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98     40426\n           1       0.86      0.67      0.75      4284\n\n    accuracy                           0.96     44710\n   macro avg       0.91      0.83      0.87     44710\nweighted avg       0.96      0.96      0.96     44710\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}